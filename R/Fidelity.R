#' Quantify group specificity of entire communities for each sample
#'
#' Function Fidelity assigns a community level specificity index to each community in the data set.The output values range from 0-1, with values closer to one indicating a community with taxa that are more host specific.
#'
#'
#' @import tidyr
#' @import magrittr
#' @import purrr
#' @import dplyr
#' @import future
#' @import future.apply
#'
#' @param comm Data frame. Data frame (or coercible to "data.frame") of community abundance values. Rows are samples, columns are taxa. Values are raw observation numbers.
#' @param groups Character. Vector of grouping levels. Must be same length as number of samples (rows) of comm.
#' @param seed Numeric of length 1. Random seed for reproducibility. Default = 666.
#' @param n.perm Positive numeric (integer) of length 1. Number of permutations for Monte Carlo permutation test. Default = 999.
#' @param pval.cutoff Positive numeric of length 1, between 0 and 1. The P-value cutoff for significance, and is used to determine thresholds for removing rare taxa. Default = 0.05.
#' @param max.ratio The maximum ratio of significant:insignificant P-values within a group. Taxa are grouped by the number of samples in which they occur. Groups in which no taxa have a significant p-value from the ISA will be flagged as a group of rare taxa. Only the first N occurrence groups that have this value or lower will be flagged for rare taxon removal. Default = 0. You are unlikely to want to change this value.
#' @param ovp.plot Logical. Should a plot of occupancy vs. p-values be generated? This will visualize the max.ratio cutoff for rare taxa removal. Default = FALSE.
#' @param rm.rare.taxa Logical. Should rare taxa be removed before the CWM? Default = TRUE. Set to FALSE if you want to perform the Community Weighted Mean analysis on all taxa.
#' @param allow.pa Logical. Should presence/absence data be allowed? Default = FALSE. Presence/absence data are not valid for this test, but users may want to run it anyway for side effects.
#'
#' @return Named List. This returns a list with 5 elements:
#' community_specificity_index = The main result showing community weighted mean for each sample, communities with greater values are more specific;
#' taxon_specificity_index = Intermediate result (`comm_name` `iv.max` `p.value` `taxon_index` `most_loyal_to`), taxa that are more host specific will have a greater taxon_index. The column "most_loyal_to" indicates the group for which that taxon had the highest loyalty;
#' isa_results = Intermediate results. taxon-level indicator species analysis with each given group level, and the indicator results for each taxon;
#' process_summary = Reports basic info on process, including the number of taxa removed due to rarity;
#' removed_taxa = Character vector with names of taxa removed due to rarity.
#'
#' @details
#' SpecifiR is a function used to assign specificity values to both individual taxa and entire communities in community data sets. This method is derived from two analyses, the Indicator Species Analysis (ISA) and a Community Weighted Mean (CWM) analysis.
#'
#' First, the permutation test of the ISA is used to assign a specificity index to each taxon. These values are generated by subtracting 1 from the p-values generated by the ISA, with values closer to 1 indicating taxa that are more specific. The analysis is based on the ISA described by DufrÃªne & Legendre (1997) and the permutation test is based on that described by McCune & Grace (2002). The taxon_specificity_index output provides a list of these taxa level indices.
#'
#' Community level specificity indices are then generated through CWM analysis using taxon level specificity indices. Values closer to one indicate communities that are more host specific. This output can be found in the community_specificity_index output.
#'
#' The user has the option of removing rare taxa from the CWM analysis. Rare taxa bias communities to appear more host specific. The rare taxa removal threshold is determined by first grouping taxa by the number of samples in which they occur, then removing the groups in which the taxa are so rare that no taxon has a significant result from the ISA. The default is for rare taxa to be removed.
#'
#' @examples
#' \donttest{
#'   set.seed(1)
#'
#'   # Use a sequential plan for examples (restore on exit)
#'   old_plan <- future::plan(future::sequential)
#'   on.exit(future::plan(old_plan), add = TRUE)
#'
#'   # Mock community and grouping data
#'   n_samples <- 30
#'   n_taxa <- 100
#'   comm_matrix <- matrix(rpois(n_samples * n_taxa, lambda = 5),
#'                         nrow = n_samples, ncol = n_taxa)
#'   colnames(comm_matrix) <- paste0("taxon.", seq_len(n_taxa))
#'   comm_df <- as.data.frame(comm_matrix)
#'
#'   # groups must match number of rows (samples)
#'   groups <- factor(rep(paste0("Group", 1:3), length.out = nrow(comm_df)))
#'
#'   # Smaller n.perm to keep examples quick and stable
#'   out <- Fidelity(comm = comm_df, groups = groups, n.perm = 199)
#'   out$community_specificity_index
#' }
#'
#' @export

Fidelity <-
  function(comm,
           groups,
           seed=666,
           n.perm=999,
           pval.cutoff=0.05,
           max.ratio=0,
           ovp.plot=FALSE,
           rm.rare.taxa=TRUE,
           allow.pa = FALSE){

  # TESTS ####



  # cross-platform parallelism
  op <- future::plan(multisession)
  on.exit(future::plan(op), add = TRUE)

  set.seed(seed)

  # helper operator
  '%ni%' <- Negate("%in%")


  # class(groups) == "character"
  if(class(groups) != "character"){
    groups <- as.character(groups)
    warning("Grouping variable converted to character class.")
  }
  # class(comm) == "data.frame" (or coercible to 'data.frame')
  # try to convert comm to data.frame
  if(!inherits(comm, "data.frame")) {
    if(is.matrix(comm)) {
      comm <- as.data.frame(comm)
      warning("comm was converted from a matrix into a data.frame")
    } else {
      stop("Community matrix must be a data.frame or matrix.")
    }
  }
  # check that community data is raw counts
  if(all(unique(rowSums(comm)) == 1)){
    warning("Looks like you have relative abundance data. Redo this with raw count data.")
  }
  # check for presence/absence data
  if (all(unique(c(as.matrix(comm))) %in% c(0, 1))) {
    if (!allow_pa) {
      stop("Input looks like presence or absence data. Set allow_pa = TRUE to override, but results will be invalid.")
    } else {
      warning("Proceeding with presence or absence data. Results will be invalid.")
    }
  }
  # check if data appear to be rarefied
  if(length(unique(rowSums(comm))) == 1){
    warning("Are your data rarefied to a uniform sampling effort? This is not advisable. It is better to incorporate sampling effort (e.g., sequencing depth) as a model term, and not to throw away your data!")
    warning("True rarefaction would require you to conduct the rarefaction step and all subsequent analyses repeatedly.")
    message("If you want to rarefy, you will need to repeat this (and any other) analysis once for each rarefaction iteration. Consider using your actual raw data instead.")
  }

  # length(groups) == nrow(comm)
  if(length(groups) != nrow(comm)){
    stop("Grouping vector is not the same length as community matrix. Community matrix must be in the format: rows=samples, cols=taxa")
  }
  # is.numeric(seed)
  if(!is.numeric(seed) | length(seed) != 1){
    stop("Random seed must be a single numeric value.")
  }
  # is.numeric(n.perm) & n.perm > 1
  if(!is.numeric(n.perm) | n.perm <= 1 | length(n.perm) != 1){
    stop("Number of permutations must be a positive integer greater than 1.")
  }
  # is.numeric(pval.cutoff) & pval.cutoff >=0 & pval.cutoff <= 1
  if(!is.numeric(pval.cutoff) | pval.cutoff < 0 | pval.cutoff > 1){
    stop("P-value cutoff must be a single number between 0 and 1.")
  }
  # is.numeric(max.ratio) & max.ratio >=0 & max.ratio <= 1
  if(!is.numeric(max.ratio) | max.ratio < 0 | max.ratio > 1){
    stop("Max ratio must be a single positive number between 0 and 1.")
  }


  # CALCULATE INDICATOR SPECIES RESULTS ####

  # This is a re-engineering of the PC-ORD indicator species analysis

  ## Step 1. Calculate relative abundance of each taxon in each group ####
  comm_sums <- colSums(comm)
  group_sums <- data.frame(comm_name = colnames(comm))
  comm$group <- groups

  # for-loop to get relabund of each taxon for each grouping level

  for(i in unique(groups)){
    comm_subset <- comm %>% dplyr::filter(group %in% i)
    comm_subset$group <- NULL
    comm_sums <- colSums(comm_subset)
    group_sums[[i]] <- comm_sums
  }

  df_rel_abund <- group_sums %>%
    rowwise() %>%
    mutate(across(
      where(is.numeric),
      ~ {
        s <- sum(c_across(where(is.numeric)))
        if (s == 0) 0 else .x / s
      }
    )) %>%
    ungroup()

  ## Step 2. calculate fidelity ####
  # proportion of samples within a given group that each taxon is found in

  # divide up by group
  # count number of samples in each group
  # count number of samples within each group that a given taxon is present
  # divide for proportion

  # make presence-absence comm table
  comm_pa <-
    comm %>%
    mutate(across(where(is.numeric), ~ if_else(.x > 0, 1, 0)))

  group_fidelity <- data.frame(comm_name = colnames(comm_pa %>% dplyr::select(-group)))

  for(i in unique(groups)){
    comm_subset <- comm_pa %>% dplyr::filter(group %in% i)
    comm_subset$group <- NULL
    comm_sums <- colSums(comm_subset)
    group_fidelity[[i]] <- comm_sums / nrow(comm_subset)
  }

  ## Step 3. multiply group_sums by group_fidelity ####

  # make matrices and add row names
  group_sum_mat <- as.matrix(df_rel_abund %>% dplyr::select(-comm_name))
  row.names(group_sum_mat) <- group_sums$comm_name
  group_fidelity_mat <- as.matrix(group_fidelity %>% dplyr::select(-comm_name))
  row.names(group_fidelity_mat) <- group_fidelity$comm_name

  # multiply matrices
  indicator_values <- group_sum_mat * group_fidelity_mat
  indicator_values <- indicator_values * 100

  # step 4. identify the highest indicator value (iv.max)
  # of the N columns, get the biggest one
  # for package, return both of these matrices (optional)


  iv.max <-
    indicator_values %>%
    apply(1, max)
  # make data frame with all indicator values and iv.max
  indicator_values <- bind_cols(indicator_values,iv.max=iv.max)
  # add back comm names
  indicator_values$taxon <- names(iv.max)

  ## Step 4. monte carlo permutations ####

  # Precompute matrices
  comm_numeric <- comm %>% dplyr::select(where(is.numeric))
  comm_matrix <- as.matrix(comm_numeric)
  comm_pa <- (comm_matrix > 0) * 1
  sample_groups <- groups
  group_levels <- unique(sample_groups)


  # Function to compute iv.max from group labels
  calc_ivmax <- function(shuffled_groups) {
    # Sum abundances by group: rows = taxa, cols = groups
    group_sums <- sapply(group_levels, function(g) {
      colSums(comm_matrix[shuffled_groups == g, , drop = FALSE])
    })
    # Ensure matrix
    group_sums <- as.matrix(group_sums)

    # SPECIFICITY: proportion of each taxon's total that sits in each group (row-wise norm)
    row_totals <- rowSums(group_sums)
    # Avoid divide-by-zero: taxa absent everywhere under this shuffle
    row_totals[row_totals == 0] <- NA
    group_sums_rel <- sweep(group_sums, 1, row_totals, "/")  # rows (taxa) sum to 1 across groups

    # FIDELITY: fraction of samples in group where taxon is present
    group_fidels <- sapply(group_levels, function(g) {
      colSums(comm_pa[shuffled_groups == g, , drop = FALSE]) / sum(shuffled_groups == g)
    })
    group_fidels <- as.matrix(group_fidels)

    # Indicator value
    # elementwise multiply, then 100. Keep orientation consistent: rows = taxa, cols = groups
    indval <- group_sums_rel * group_fidels
    indval[is.na(indval)] <- 0
    indval <- indval * 100

    # iv.max per taxon (max across groups)
    apply(indval, 1, max)
  }

  # Observed iv.max
  iv.max_obs <- calc_ivmax(sample_groups)


  # Permuted iv.max values
  RNGkind("L'Ecuyer-CMRG")
  iv.max_perm <- future_replicate(
    n.perm,
    calc_ivmax(sample(sample_groups)),
    future.seed = TRUE  # moved this from item 3 but safe here too
  )
  #assign(x = "iv_max_perm",iv.max_perm,envir = .GlobalEnv)

  # Empirical p-values
  iv.pval <- rowMeans(iv.max_perm >= iv.max_obs)

  # Output result
  indicator_results <- tibble(
    comm_name = colnames(comm_matrix),
    iv.max = iv.max_obs,
    p.value = iv.pval
  )


  # PREP FOR CWM ####

  ## convert to presence-absence ####
  comm_pa <- comm %>% dplyr::select(-group)
  comm_pa[comm_pa>0] <- 1

  ## get occurrence values ####
  indicator_results[["occurrence"]] <- colSums(comm_pa)

  # REMOVE RARE TAXA ####

  # We already have indicator_results$occurrence (integer counts)
  # Build the ratio table BY OCCURRENCE, not factor positions
  ratio_df <- indicator_results %>%
    mutate(significant = p.value <= pval.cutoff) %>%
    group_by(occurrence) %>%
    summarize(
      ratio   = sum(significant) / sum(!significant),
      n_sig   = sum(significant),
      n_insig = sum(!significant),
      .groups = "drop"
    )

  # Deal with Inf (all significant), treat as 1 (the maximum possible ratio)
  ratio_df$ratio[is.infinite(ratio_df$ratio)] <- 1

  # Determine the cutoff: largest occurrence whose ratio <= max.ratio
  drop_occs <- ratio_df$occurrence[ratio_df$ratio <= max.ratio]
  occurrence_cutoff <- if (length(drop_occs)) max(drop_occs) else 0

  # OPTIONAL OCCUPANCY VS P.VALUE PLOT ####
  if (ovp.plot && occurrence_cutoff > 0) {
    p <-
      indicator_results %>%
      ggplot(aes(x = occurrence, y = p.value, color = iv.max)) +
      geom_point(size = 2, alpha = ifelse(nrow(indicator_results) > 1000, .75, 1)) +
      labs(x = "Number of site occurrences", y = "P value", color = "Indicator\nvalue") +
      geom_hline(yintercept = pval.cutoff, linetype = 2) +
      geom_vline(xintercept = occurrence_cutoff, linetype = 2) +
      scale_color_viridis_c(end = .9) +
      theme_bw()
    print(p)
  }

  if (rm.rare.taxa && occurrence_cutoff > 0) {
    # subset indicator results by actual occurrence counts
    isa_subset <- indicator_results %>% filter(occurrence > occurrence_cutoff)

    # subset comm to match (preserve shape)
    comm_subset <- comm[, colnames(comm) %in% isa_subset$comm_name, drop = FALSE]

    # find removed taxa (exclude the injected 'group' column if present)
    starting_taxa <- setdiff(colnames(comm), "group")
    removed_taxa  <- setdiff(starting_taxa, colnames(comm_subset))

    message(paste0("Removed taxa present in ", occurrence_cutoff, " sites or fewer."))
  } else {
    isa_subset <- indicator_results
    comm_subset <- comm
    comm$group <- NULL
    comm_subset$group <- NULL
    removed_taxa <- character(0)
  }

  # calculate taxon index (so bigger indicates more indicative)
  isa_subset$taxon_index <- 1 - isa_subset$p.value

  # PERFORM CWM ANALYSIS ####
  cwm <- makecwm(comm_subset, isa_subset[["taxon_index"]])

  # clean it up to make a more usable object
  output <- data.frame(sample_id = row.names(cwm),
                       community_index = cwm[["V1"]],
                       group = groups)

  # add taxon index to results
  indicator_results$taxon_index <- 1 - indicator_results$p.value
  # clean up data frame a bit
  indicator_results$occurrence <- NULL

  comm_subset_num <- comm_subset
  if ("group" %in% colnames(comm_subset_num)) {
    comm_subset_num <- comm_subset_num[, setdiff(colnames(comm_subset_num), "group"), drop = FALSE]
  }

  # create process summary
  process_summary <-
    data.frame(
      n_samples_start    = nrow(comm_matrix),
      n_samples_end      = nrow(comm_subset),
      n_taxa_start       = ncol(comm_matrix),
      n_taxa_end         = ncol(comm_subset_num),
      n_raretaxa_removed = ncol(comm_matrix) - ncol(comm_subset_num),
      occurrence_cutoff  = occurrence_cutoff,
      pval_cutoff        = pval.cutoff,
      n_perm             = n.perm
    )

  # clean up indicator results to show group of highest "loyalty" per taxon
  indicator_df <- as_tibble(as.data.frame(indicator_values), .name_repair = "minimal")
  # do NOT overwrite 'taxon' here; it already exists in indicator_values

  # Put groups in a known order (same as group_levels), then add iv.max from obs
  indicator_df <- indicator_df %>%
    relocate(all_of(group_levels), .before = everything()) %>%
    mutate(iv.max = iv.max_obs) %>%
    relocate(taxon, .before = everything())

  # Select strictly numeric group columns for the search matrix
  search <- indicator_df %>% select(all_of(group_levels))  # numeric only

  # Compute most-loyal group using the trusted maxima
  M <- abs(as.matrix(search) - iv.max_obs) < 1e-9
  idx <- max.col(M, ties.method = "first")     # tie-breaker = first group
  idx[rowSums(M) == 0] <- NA_integer_          # no exact match (should be rare)
  indicator_df$most_loyal_to <- colnames(search)[idx]

  # Push this back into results
  indicator_results$most_loyal_to <- indicator_df$most_loyal_to


  # create output object (list)
  out <- list(community_specificity_index = output,
              taxon_specificity_index = indicator_results,
              isa_results = indicator_df,
              process_summary = process_summary,
              removed_taxa = removed_taxa)


  return(out)

}
